# -*- coding: utf-8 -*-
"""data_prep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yn86vqSHV5qyoJ-jJ4meQgZMCtubz6o5

# **Preprocesamiento (limpieza y features)**
"""

import pandas as pd
import numpy as np

df = pd.read_parquet("nyc_sample.parquet")
print("Columnas disponibles:", df.columns.tolist())

# Normalizar nombres más comunes de columnas (varían según año)
# Intentar detectar nombres para pickup datetime, location ids y coords
possible_pickup_cols = [c for c in df.columns if 'pickup' in c.lower() and 'datetime' in c.lower()]
possible_dropoff_cols = [c for c in df.columns if 'dropoff' in c.lower() and 'datetime' in c.lower()]

print("Pickup cols candidate:", possible_pickup_cols)
pickup_col = possible_pickup_cols[0] if possible_pickup_cols else None
dropoff_col = possible_dropoff_cols[0] if possible_dropoff_cols else None

# Location ID cols (PULocationID, PULocationID etc.)
# Note: los archivos antiguos podrían no tener PULocationID, pero usar lat/lon directamente.
loc_cols = [c for c in df.columns if 'pulocationid' in c.lower() or 'pickup_locationid' in c.lower() or 'locationid' in c.lower()]
print("Location ID candidates:", loc_cols)
pu_loc_id_col = loc_cols[0] if loc_cols else None

# Coordenadas
lat_cols = [c for c in df.columns if 'pickup_lat' in c.lower() or 'pickup_latitude' in c.lower()]
lon_cols = [c for c in df.columns if 'pickup_lon' in c.lower() or 'pickup_longitude' in c.lower()]
pu_lat = lat_cols[0] if lat_cols else None
pu_lon = lon_cols[0] if lon_cols else None

# Renombramiento básico a nombres canónicos
if pickup_col:
    df.rename(columns={pickup_col: "tpep_pickup_datetime"}, inplace=True)
if dropoff_col:
    df.rename(columns={dropoff_col: "tpep_dropoff_datetime"}, inplace=True)

# Si la columna location ID se encuentra, renombrarla a PULocationID
if pu_loc_id_col:
    df.rename(columns={pu_loc_id_col: "PULocationID"}, inplace=True)
    # Convertir location id a entero (int) de ser posible
    try:
        df["PULocationID"] = df["PULocationID"].astype(int)
    except Exception as e:
        print(f"Warning: Could not convert 'PULocationID' to int: {e}, keeping original type.")

# Si PULocationID aún no está en df.columns, crear sintaxis de lat/lon
if "PULocationID" not in df.columns and pu_lat and pu_lon:
    print("Warning: 'PULocationID' not found in the dataset. Creating synthetic 'PULocationID' from binned latitude and longitude.")
    # Agrupar la latitud y la longitud para crear una identificación de zona pseudoaleatoria
    # Un tamaño de bin de 0,01 grados de latitud equivale aproximadamente a 1,1 km.
    # Ajustar `round_to` para obtener la granularidad deseada. 2 significa 2 decimales.
    round_to = 2
    df["PULocationID"] = (df["pickup_latitude"].round(round_to)).astype(str) + "_" + \
                         (df["pickup_longitude"].round(round_to)).astype(str)
    print(f"Synthetic 'PULocationID' created using binned lat/lon (rounded to {round_to} decimal places).")
elif "PULocationID" not in df.columns:
    print("Warning: Neither 'PULocationID' nor valid latitude/longitude columns found to create a location identifier for grouping.")

# Si se encontraron coordenadas, renómbralas con nombres canónicos
if pu_lat:
    df.rename(columns={pu_lat: "pickup_latitude"}, inplace=True)
if pu_lon:
    df.rename(columns={pu_lon: "pickup_longitude"}, inplace=True)


# Convertir datetimes y crear features temporales
df["tpep_pickup_datetime"] = pd.to_datetime(df["tpep_pickup_datetime"], errors="coerce")
df = df.dropna(subset=["tpep_pickup_datetime"])

df["pickup_hour"] = df["tpep_pickup_datetime"].dt.hour
df["pickup_day"] = df["tpep_pickup_datetime"].dt.dayofweek  # 0=Monday
df["pickup_date"] = df["tpep_pickup_datetime"].dt.date
df["pickup_month"] = df["tpep_pickup_datetime"].dt.month

# Duración del recorrido (min) si existe parada
if "tpep_dropoff_datetime" in df.columns:
    df["tpep_dropoff_datetime"] = pd.to_datetime(df["tpep_dropoff_datetime"], errors="coerce")
    df["trip_duration_min"] = (df["tpep_dropoff_datetime"] - df["tpep_pickup_datetime"]).dt.total_seconds() / 60.0

# Recurrir a la distancia del viaje
if "trip_distance" not in df.columns and "Trip_distance" in df.columns:
    df.rename(columns={"Trip_distance":"trip_distance"}, inplace=True)

# Filtrar viajes válidos
if "trip_duration_min" in df.columns:
    df = df[(df["trip_duration_min"]>0) & (df["trip_duration_min"]<180)]

# Gestionar el filtrado de ubicaciones nulas en función de lo que esté disponible
if "PULocationID" in df.columns:
    df = df[df["PULocationID"].notnull()]
elif "pickup_latitude" in df.columns and "pickup_longitude" in df.columns:
    print("No 'PULocationID' found, filtering based on 'pickup_latitude' and 'pickup_longitude' not being null.")
    df = df[df["pickup_latitude"].notnull() & df["pickup_longitude"].notnull()]
else:
    print("Warning: No 'PULocationID' or valid latitude/longitude columns found for location filtering.")


print("After preprocessing rows:", len(df))
df.head()
# Guardar el preprocesado (opcional)
df.to_parquet("nyc_preprocessed.parquet", index=False)
# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R7OcqQ3Q3XI-BpW7c_92yzMtIBrZgonQ

# **Preparar features para ML (sk-learn + RandomForest)**
"""

# Preparar la tabla de entrenamiento de la demanda original (zone+date+hour)
train_tbl = demand.copy()
# Agregar el atributo month de pickup_date (convertir)
train_tbl["month"] = pd.to_datetime(train_tbl["pickup_date"]).dt.month
train_tbl["dow"] = pd.to_datetime(train_tbl["pickup_date"]).dt.dayofweek

# Para el modelado, agregar por zone+hour+month+dow -> predecir viajes (contar)
X = train_tbl[["PULocationID", "pickup_hour", "month", "dow"]]
y = train_tbl["trips"]

# Codificar PULocationID como ordinal para mantener un pipeline simple
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

enc = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)
X_enc = X.copy()
X_enc["PULocationID_enc"] = enc.fit_transform(X[["PULocationID"]])
X_enc = X_enc[["PULocationID_enc", "pickup_hour", "month", "dow"]]

X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=0.2, random_state=42)

rf = RandomForestRegressor(n_estimators=100, max_depth=12, n_jobs=-1, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
print(f"RF RMSE: {rmse:.3f}  MAE: {mae:.3f}")

# Guadar el modelo y el encoder
import joblib
joblib.dump(rf, "rf_demand_model.joblib")
joblib.dump(enc, "ordinal_encoder.joblib")
print("Model and encoder saved.")

"""# **(Opcional) Modelo TensorFlow ligero**

(Opcional dado que RandomForest suele ser suficiente y más interpretable).
"""

# Versión ligera con TF (opcional) — entrenar una red densa pequeña sobre mismas features
import tensorflow as tf
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_enc)

Xtr, Xte, ytr, yte = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(Xtr.shape[1],)),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(32, activation="relu"),
    tf.keras.layers.Dense(1)
])
model.compile(optimizer="adam", loss="mse", metrics=["mae"])
model.fit(Xtr, ytr, validation_data=(Xte, yte), epochs=5, batch_size=1024)

# Guardar modelo TF y scaler
model.save("tf_demand_model.keras")
joblib.dump(scaler, "scaler.joblib")
print("TF model and scaler saved.")